{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0125,
      "grad_norm": 7.151899814605713,
      "learning_rate": 0.00019885,
      "loss": 4.1773,
      "step": 50
    },
    {
      "epoch": 0.025,
      "grad_norm": 6.953211784362793,
      "learning_rate": 0.0001976,
      "loss": 3.8582,
      "step": 100
    },
    {
      "epoch": 0.0375,
      "grad_norm": 7.440255165100098,
      "learning_rate": 0.00019635,
      "loss": 3.5754,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.580025672912598,
      "learning_rate": 0.000195125,
      "loss": 3.4932,
      "step": 200
    },
    {
      "epoch": 0.0625,
      "grad_norm": 6.704347133636475,
      "learning_rate": 0.000193875,
      "loss": 3.4936,
      "step": 250
    },
    {
      "epoch": 0.075,
      "grad_norm": 5.5381951332092285,
      "learning_rate": 0.000192625,
      "loss": 3.4465,
      "step": 300
    },
    {
      "epoch": 0.0875,
      "grad_norm": 7.55710506439209,
      "learning_rate": 0.000191375,
      "loss": 3.3749,
      "step": 350
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.992891788482666,
      "learning_rate": 0.00019012500000000003,
      "loss": 3.3782,
      "step": 400
    },
    {
      "epoch": 0.1125,
      "grad_norm": 6.051767349243164,
      "learning_rate": 0.000188875,
      "loss": 3.2823,
      "step": 450
    },
    {
      "epoch": 0.125,
      "grad_norm": 6.564311504364014,
      "learning_rate": 0.000187625,
      "loss": 3.383,
      "step": 500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 5.3335418701171875,
      "learning_rate": 0.00018637500000000002,
      "loss": 3.2238,
      "step": 550
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.568899154663086,
      "learning_rate": 0.00018512500000000001,
      "loss": 3.4571,
      "step": 600
    },
    {
      "epoch": 0.1625,
      "grad_norm": 7.294872283935547,
      "learning_rate": 0.000183875,
      "loss": 3.3276,
      "step": 650
    },
    {
      "epoch": 0.175,
      "grad_norm": 8.290392875671387,
      "learning_rate": 0.000182625,
      "loss": 3.2568,
      "step": 700
    },
    {
      "epoch": 0.1875,
      "grad_norm": 7.649342060089111,
      "learning_rate": 0.000181375,
      "loss": 3.102,
      "step": 750
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.80737829208374,
      "learning_rate": 0.000180125,
      "loss": 3.2364,
      "step": 800
    },
    {
      "epoch": 0.2125,
      "grad_norm": 6.590611457824707,
      "learning_rate": 0.00017887500000000002,
      "loss": 3.3411,
      "step": 850
    },
    {
      "epoch": 0.225,
      "grad_norm": 7.614189624786377,
      "learning_rate": 0.00017762500000000002,
      "loss": 3.1145,
      "step": 900
    },
    {
      "epoch": 0.2375,
      "grad_norm": 6.320446014404297,
      "learning_rate": 0.000176375,
      "loss": 3.0597,
      "step": 950
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.057395935058594,
      "learning_rate": 0.00017512500000000001,
      "loss": 3.1337,
      "step": 1000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 5.739480495452881,
      "learning_rate": 0.000173875,
      "loss": 3.0451,
      "step": 1050
    },
    {
      "epoch": 0.275,
      "grad_norm": 7.39730167388916,
      "learning_rate": 0.000172625,
      "loss": 3.1963,
      "step": 1100
    },
    {
      "epoch": 0.2875,
      "grad_norm": 5.989907264709473,
      "learning_rate": 0.00017137500000000003,
      "loss": 3.1608,
      "step": 1150
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.021162033081055,
      "learning_rate": 0.000170125,
      "loss": 3.0031,
      "step": 1200
    },
    {
      "epoch": 0.3125,
      "grad_norm": 7.2478346824646,
      "learning_rate": 0.000168875,
      "loss": 3.1138,
      "step": 1250
    },
    {
      "epoch": 0.325,
      "grad_norm": 8.351295471191406,
      "learning_rate": 0.00016762500000000002,
      "loss": 3.067,
      "step": 1300
    },
    {
      "epoch": 0.3375,
      "grad_norm": 7.790977954864502,
      "learning_rate": 0.00016637500000000002,
      "loss": 3.1976,
      "step": 1350
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.671870231628418,
      "learning_rate": 0.00016512500000000002,
      "loss": 3.13,
      "step": 1400
    },
    {
      "epoch": 0.3625,
      "grad_norm": 5.449990749359131,
      "learning_rate": 0.000163875,
      "loss": 3.036,
      "step": 1450
    },
    {
      "epoch": 0.375,
      "grad_norm": 6.424103260040283,
      "learning_rate": 0.000162625,
      "loss": 3.0089,
      "step": 1500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 6.413305759429932,
      "learning_rate": 0.000161375,
      "loss": 3.0331,
      "step": 1550
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.9596476554870605,
      "learning_rate": 0.000160125,
      "loss": 3.011,
      "step": 1600
    },
    {
      "epoch": 0.4125,
      "grad_norm": 5.290374755859375,
      "learning_rate": 0.00015887500000000003,
      "loss": 2.9846,
      "step": 1650
    },
    {
      "epoch": 0.425,
      "grad_norm": 8.068273544311523,
      "learning_rate": 0.000157625,
      "loss": 2.9495,
      "step": 1700
    },
    {
      "epoch": 0.4375,
      "grad_norm": 8.307579040527344,
      "learning_rate": 0.000156375,
      "loss": 2.9649,
      "step": 1750
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.057717800140381,
      "learning_rate": 0.00015512500000000002,
      "loss": 3.2023,
      "step": 1800
    },
    {
      "epoch": 0.4625,
      "grad_norm": 5.899886131286621,
      "learning_rate": 0.000153875,
      "loss": 3.1122,
      "step": 1850
    },
    {
      "epoch": 0.475,
      "grad_norm": 6.930113792419434,
      "learning_rate": 0.000152625,
      "loss": 2.9091,
      "step": 1900
    },
    {
      "epoch": 0.4875,
      "grad_norm": 7.770974636077881,
      "learning_rate": 0.000151375,
      "loss": 2.8587,
      "step": 1950
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.176039695739746,
      "learning_rate": 0.000150125,
      "loss": 3.1193,
      "step": 2000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 5.593860626220703,
      "learning_rate": 0.000148875,
      "loss": 2.9407,
      "step": 2050
    },
    {
      "epoch": 0.525,
      "grad_norm": 8.361449241638184,
      "learning_rate": 0.00014762500000000002,
      "loss": 3.1221,
      "step": 2100
    },
    {
      "epoch": 0.5375,
      "grad_norm": 5.408958911895752,
      "learning_rate": 0.00014637500000000002,
      "loss": 2.945,
      "step": 2150
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.462265491485596,
      "learning_rate": 0.000145125,
      "loss": 2.9978,
      "step": 2200
    },
    {
      "epoch": 0.5625,
      "grad_norm": 8.306090354919434,
      "learning_rate": 0.0001439,
      "loss": 2.9327,
      "step": 2250
    },
    {
      "epoch": 0.575,
      "grad_norm": 7.500792980194092,
      "learning_rate": 0.00014265000000000003,
      "loss": 2.9387,
      "step": 2300
    },
    {
      "epoch": 0.5875,
      "grad_norm": 9.017549514770508,
      "learning_rate": 0.0001414,
      "loss": 2.841,
      "step": 2350
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.975734233856201,
      "learning_rate": 0.00014015,
      "loss": 2.836,
      "step": 2400
    },
    {
      "epoch": 0.6125,
      "grad_norm": 5.7256999015808105,
      "learning_rate": 0.00013890000000000002,
      "loss": 2.9963,
      "step": 2450
    },
    {
      "epoch": 0.625,
      "grad_norm": 6.078909873962402,
      "learning_rate": 0.00013765,
      "loss": 2.8665,
      "step": 2500
    },
    {
      "epoch": 0.6375,
      "grad_norm": 7.809144973754883,
      "learning_rate": 0.0001364,
      "loss": 2.9493,
      "step": 2550
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.581154823303223,
      "learning_rate": 0.00013515,
      "loss": 2.9491,
      "step": 2600
    },
    {
      "epoch": 0.6625,
      "grad_norm": 7.749644756317139,
      "learning_rate": 0.0001339,
      "loss": 2.989,
      "step": 2650
    },
    {
      "epoch": 0.675,
      "grad_norm": 6.636688709259033,
      "learning_rate": 0.00013265,
      "loss": 2.8873,
      "step": 2700
    },
    {
      "epoch": 0.6875,
      "grad_norm": 8.353581428527832,
      "learning_rate": 0.00013140000000000002,
      "loss": 3.0142,
      "step": 2750
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.629694938659668,
      "learning_rate": 0.00013015000000000002,
      "loss": 2.9795,
      "step": 2800
    },
    {
      "epoch": 0.7125,
      "grad_norm": 9.068134307861328,
      "learning_rate": 0.0001289,
      "loss": 2.9392,
      "step": 2850
    },
    {
      "epoch": 0.725,
      "grad_norm": 6.031069278717041,
      "learning_rate": 0.00012765,
      "loss": 2.9201,
      "step": 2900
    },
    {
      "epoch": 0.7375,
      "grad_norm": 7.2104411125183105,
      "learning_rate": 0.0001264,
      "loss": 2.8283,
      "step": 2950
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.649674892425537,
      "learning_rate": 0.00012515,
      "loss": 2.8866,
      "step": 3000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 8.334878921508789,
      "learning_rate": 0.0001239,
      "loss": 2.8442,
      "step": 3050
    },
    {
      "epoch": 0.775,
      "grad_norm": 6.063122749328613,
      "learning_rate": 0.00012265,
      "loss": 2.9733,
      "step": 3100
    },
    {
      "epoch": 0.7875,
      "grad_norm": 6.480292797088623,
      "learning_rate": 0.0001214,
      "loss": 2.7681,
      "step": 3150
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.98184061050415,
      "learning_rate": 0.00012015,
      "loss": 2.7658,
      "step": 3200
    },
    {
      "epoch": 0.8125,
      "grad_norm": 7.397098064422607,
      "learning_rate": 0.00011890000000000002,
      "loss": 2.9743,
      "step": 3250
    },
    {
      "epoch": 0.825,
      "grad_norm": 6.729558944702148,
      "learning_rate": 0.00011765000000000001,
      "loss": 2.8777,
      "step": 3300
    },
    {
      "epoch": 0.8375,
      "grad_norm": 5.1290812492370605,
      "learning_rate": 0.0001164,
      "loss": 2.8144,
      "step": 3350
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.6252570152282715,
      "learning_rate": 0.00011515000000000001,
      "loss": 2.9417,
      "step": 3400
    },
    {
      "epoch": 0.8625,
      "grad_norm": 7.118127346038818,
      "learning_rate": 0.0001139,
      "loss": 2.6817,
      "step": 3450
    },
    {
      "epoch": 0.875,
      "grad_norm": 6.379133701324463,
      "learning_rate": 0.00011265000000000001,
      "loss": 2.8424,
      "step": 3500
    },
    {
      "epoch": 0.8875,
      "grad_norm": 6.037752628326416,
      "learning_rate": 0.00011140000000000001,
      "loss": 2.9202,
      "step": 3550
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.932679653167725,
      "learning_rate": 0.00011015,
      "loss": 2.8381,
      "step": 3600
    },
    {
      "epoch": 0.9125,
      "grad_norm": 7.722475051879883,
      "learning_rate": 0.0001089,
      "loss": 2.788,
      "step": 3650
    },
    {
      "epoch": 0.925,
      "grad_norm": 5.824307918548584,
      "learning_rate": 0.00010765,
      "loss": 2.9159,
      "step": 3700
    },
    {
      "epoch": 0.9375,
      "grad_norm": 8.152589797973633,
      "learning_rate": 0.00010640000000000001,
      "loss": 2.7495,
      "step": 3750
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.885190486907959,
      "learning_rate": 0.00010515000000000002,
      "loss": 2.6902,
      "step": 3800
    },
    {
      "epoch": 0.9625,
      "grad_norm": 8.480701446533203,
      "learning_rate": 0.00010389999999999999,
      "loss": 2.6678,
      "step": 3850
    },
    {
      "epoch": 0.975,
      "grad_norm": 6.438226222991943,
      "learning_rate": 0.00010265,
      "loss": 2.7699,
      "step": 3900
    },
    {
      "epoch": 0.9875,
      "grad_norm": 6.921266555786133,
      "learning_rate": 0.00010140000000000001,
      "loss": 2.8913,
      "step": 3950
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.703295707702637,
      "learning_rate": 0.00010015000000000001,
      "loss": 2.7655,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.7956972122192383,
      "eval_runtime": 17.2901,
      "eval_samples_per_second": 115.673,
      "eval_steps_per_second": 28.918,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2651426525846784.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
