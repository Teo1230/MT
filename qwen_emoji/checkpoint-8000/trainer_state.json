{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0125,
      "grad_norm": 7.151899814605713,
      "learning_rate": 0.00019885,
      "loss": 4.1773,
      "step": 50
    },
    {
      "epoch": 0.025,
      "grad_norm": 6.953211784362793,
      "learning_rate": 0.0001976,
      "loss": 3.8582,
      "step": 100
    },
    {
      "epoch": 0.0375,
      "grad_norm": 7.440255165100098,
      "learning_rate": 0.00019635,
      "loss": 3.5754,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.580025672912598,
      "learning_rate": 0.000195125,
      "loss": 3.4932,
      "step": 200
    },
    {
      "epoch": 0.0625,
      "grad_norm": 6.704347133636475,
      "learning_rate": 0.000193875,
      "loss": 3.4936,
      "step": 250
    },
    {
      "epoch": 0.075,
      "grad_norm": 5.5381951332092285,
      "learning_rate": 0.000192625,
      "loss": 3.4465,
      "step": 300
    },
    {
      "epoch": 0.0875,
      "grad_norm": 7.55710506439209,
      "learning_rate": 0.000191375,
      "loss": 3.3749,
      "step": 350
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.992891788482666,
      "learning_rate": 0.00019012500000000003,
      "loss": 3.3782,
      "step": 400
    },
    {
      "epoch": 0.1125,
      "grad_norm": 6.051767349243164,
      "learning_rate": 0.000188875,
      "loss": 3.2823,
      "step": 450
    },
    {
      "epoch": 0.125,
      "grad_norm": 6.564311504364014,
      "learning_rate": 0.000187625,
      "loss": 3.383,
      "step": 500
    },
    {
      "epoch": 0.1375,
      "grad_norm": 5.3335418701171875,
      "learning_rate": 0.00018637500000000002,
      "loss": 3.2238,
      "step": 550
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.568899154663086,
      "learning_rate": 0.00018512500000000001,
      "loss": 3.4571,
      "step": 600
    },
    {
      "epoch": 0.1625,
      "grad_norm": 7.294872283935547,
      "learning_rate": 0.000183875,
      "loss": 3.3276,
      "step": 650
    },
    {
      "epoch": 0.175,
      "grad_norm": 8.290392875671387,
      "learning_rate": 0.000182625,
      "loss": 3.2568,
      "step": 700
    },
    {
      "epoch": 0.1875,
      "grad_norm": 7.649342060089111,
      "learning_rate": 0.000181375,
      "loss": 3.102,
      "step": 750
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.80737829208374,
      "learning_rate": 0.000180125,
      "loss": 3.2364,
      "step": 800
    },
    {
      "epoch": 0.2125,
      "grad_norm": 6.590611457824707,
      "learning_rate": 0.00017887500000000002,
      "loss": 3.3411,
      "step": 850
    },
    {
      "epoch": 0.225,
      "grad_norm": 7.614189624786377,
      "learning_rate": 0.00017762500000000002,
      "loss": 3.1145,
      "step": 900
    },
    {
      "epoch": 0.2375,
      "grad_norm": 6.320446014404297,
      "learning_rate": 0.000176375,
      "loss": 3.0597,
      "step": 950
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.057395935058594,
      "learning_rate": 0.00017512500000000001,
      "loss": 3.1337,
      "step": 1000
    },
    {
      "epoch": 0.2625,
      "grad_norm": 5.739480495452881,
      "learning_rate": 0.000173875,
      "loss": 3.0451,
      "step": 1050
    },
    {
      "epoch": 0.275,
      "grad_norm": 7.39730167388916,
      "learning_rate": 0.000172625,
      "loss": 3.1963,
      "step": 1100
    },
    {
      "epoch": 0.2875,
      "grad_norm": 5.989907264709473,
      "learning_rate": 0.00017137500000000003,
      "loss": 3.1608,
      "step": 1150
    },
    {
      "epoch": 0.3,
      "grad_norm": 5.021162033081055,
      "learning_rate": 0.000170125,
      "loss": 3.0031,
      "step": 1200
    },
    {
      "epoch": 0.3125,
      "grad_norm": 7.2478346824646,
      "learning_rate": 0.000168875,
      "loss": 3.1138,
      "step": 1250
    },
    {
      "epoch": 0.325,
      "grad_norm": 8.351295471191406,
      "learning_rate": 0.00016762500000000002,
      "loss": 3.067,
      "step": 1300
    },
    {
      "epoch": 0.3375,
      "grad_norm": 7.790977954864502,
      "learning_rate": 0.00016637500000000002,
      "loss": 3.1976,
      "step": 1350
    },
    {
      "epoch": 0.35,
      "grad_norm": 6.671870231628418,
      "learning_rate": 0.00016512500000000002,
      "loss": 3.13,
      "step": 1400
    },
    {
      "epoch": 0.3625,
      "grad_norm": 5.449990749359131,
      "learning_rate": 0.000163875,
      "loss": 3.036,
      "step": 1450
    },
    {
      "epoch": 0.375,
      "grad_norm": 6.424103260040283,
      "learning_rate": 0.000162625,
      "loss": 3.0089,
      "step": 1500
    },
    {
      "epoch": 0.3875,
      "grad_norm": 6.413305759429932,
      "learning_rate": 0.000161375,
      "loss": 3.0331,
      "step": 1550
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.9596476554870605,
      "learning_rate": 0.000160125,
      "loss": 3.011,
      "step": 1600
    },
    {
      "epoch": 0.4125,
      "grad_norm": 5.290374755859375,
      "learning_rate": 0.00015887500000000003,
      "loss": 2.9846,
      "step": 1650
    },
    {
      "epoch": 0.425,
      "grad_norm": 8.068273544311523,
      "learning_rate": 0.000157625,
      "loss": 2.9495,
      "step": 1700
    },
    {
      "epoch": 0.4375,
      "grad_norm": 8.307579040527344,
      "learning_rate": 0.000156375,
      "loss": 2.9649,
      "step": 1750
    },
    {
      "epoch": 0.45,
      "grad_norm": 7.057717800140381,
      "learning_rate": 0.00015512500000000002,
      "loss": 3.2023,
      "step": 1800
    },
    {
      "epoch": 0.4625,
      "grad_norm": 5.899886131286621,
      "learning_rate": 0.000153875,
      "loss": 3.1122,
      "step": 1850
    },
    {
      "epoch": 0.475,
      "grad_norm": 6.930113792419434,
      "learning_rate": 0.000152625,
      "loss": 2.9091,
      "step": 1900
    },
    {
      "epoch": 0.4875,
      "grad_norm": 7.770974636077881,
      "learning_rate": 0.000151375,
      "loss": 2.8587,
      "step": 1950
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.176039695739746,
      "learning_rate": 0.000150125,
      "loss": 3.1193,
      "step": 2000
    },
    {
      "epoch": 0.5125,
      "grad_norm": 5.593860626220703,
      "learning_rate": 0.000148875,
      "loss": 2.9407,
      "step": 2050
    },
    {
      "epoch": 0.525,
      "grad_norm": 8.361449241638184,
      "learning_rate": 0.00014762500000000002,
      "loss": 3.1221,
      "step": 2100
    },
    {
      "epoch": 0.5375,
      "grad_norm": 5.408958911895752,
      "learning_rate": 0.00014637500000000002,
      "loss": 2.945,
      "step": 2150
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.462265491485596,
      "learning_rate": 0.000145125,
      "loss": 2.9978,
      "step": 2200
    },
    {
      "epoch": 0.5625,
      "grad_norm": 8.306090354919434,
      "learning_rate": 0.0001439,
      "loss": 2.9327,
      "step": 2250
    },
    {
      "epoch": 0.575,
      "grad_norm": 7.500792980194092,
      "learning_rate": 0.00014265000000000003,
      "loss": 2.9387,
      "step": 2300
    },
    {
      "epoch": 0.5875,
      "grad_norm": 9.017549514770508,
      "learning_rate": 0.0001414,
      "loss": 2.841,
      "step": 2350
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.975734233856201,
      "learning_rate": 0.00014015,
      "loss": 2.836,
      "step": 2400
    },
    {
      "epoch": 0.6125,
      "grad_norm": 5.7256999015808105,
      "learning_rate": 0.00013890000000000002,
      "loss": 2.9963,
      "step": 2450
    },
    {
      "epoch": 0.625,
      "grad_norm": 6.078909873962402,
      "learning_rate": 0.00013765,
      "loss": 2.8665,
      "step": 2500
    },
    {
      "epoch": 0.6375,
      "grad_norm": 7.809144973754883,
      "learning_rate": 0.0001364,
      "loss": 2.9493,
      "step": 2550
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.581154823303223,
      "learning_rate": 0.00013515,
      "loss": 2.9491,
      "step": 2600
    },
    {
      "epoch": 0.6625,
      "grad_norm": 7.749644756317139,
      "learning_rate": 0.0001339,
      "loss": 2.989,
      "step": 2650
    },
    {
      "epoch": 0.675,
      "grad_norm": 6.636688709259033,
      "learning_rate": 0.00013265,
      "loss": 2.8873,
      "step": 2700
    },
    {
      "epoch": 0.6875,
      "grad_norm": 8.353581428527832,
      "learning_rate": 0.00013140000000000002,
      "loss": 3.0142,
      "step": 2750
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.629694938659668,
      "learning_rate": 0.00013015000000000002,
      "loss": 2.9795,
      "step": 2800
    },
    {
      "epoch": 0.7125,
      "grad_norm": 9.068134307861328,
      "learning_rate": 0.0001289,
      "loss": 2.9392,
      "step": 2850
    },
    {
      "epoch": 0.725,
      "grad_norm": 6.031069278717041,
      "learning_rate": 0.00012765,
      "loss": 2.9201,
      "step": 2900
    },
    {
      "epoch": 0.7375,
      "grad_norm": 7.2104411125183105,
      "learning_rate": 0.0001264,
      "loss": 2.8283,
      "step": 2950
    },
    {
      "epoch": 0.75,
      "grad_norm": 5.649674892425537,
      "learning_rate": 0.00012515,
      "loss": 2.8866,
      "step": 3000
    },
    {
      "epoch": 0.7625,
      "grad_norm": 8.334878921508789,
      "learning_rate": 0.0001239,
      "loss": 2.8442,
      "step": 3050
    },
    {
      "epoch": 0.775,
      "grad_norm": 6.063122749328613,
      "learning_rate": 0.00012265,
      "loss": 2.9733,
      "step": 3100
    },
    {
      "epoch": 0.7875,
      "grad_norm": 6.480292797088623,
      "learning_rate": 0.0001214,
      "loss": 2.7681,
      "step": 3150
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.98184061050415,
      "learning_rate": 0.00012015,
      "loss": 2.7658,
      "step": 3200
    },
    {
      "epoch": 0.8125,
      "grad_norm": 7.397098064422607,
      "learning_rate": 0.00011890000000000002,
      "loss": 2.9743,
      "step": 3250
    },
    {
      "epoch": 0.825,
      "grad_norm": 6.729558944702148,
      "learning_rate": 0.00011765000000000001,
      "loss": 2.8777,
      "step": 3300
    },
    {
      "epoch": 0.8375,
      "grad_norm": 5.1290812492370605,
      "learning_rate": 0.0001164,
      "loss": 2.8144,
      "step": 3350
    },
    {
      "epoch": 0.85,
      "grad_norm": 7.6252570152282715,
      "learning_rate": 0.00011515000000000001,
      "loss": 2.9417,
      "step": 3400
    },
    {
      "epoch": 0.8625,
      "grad_norm": 7.118127346038818,
      "learning_rate": 0.0001139,
      "loss": 2.6817,
      "step": 3450
    },
    {
      "epoch": 0.875,
      "grad_norm": 6.379133701324463,
      "learning_rate": 0.00011265000000000001,
      "loss": 2.8424,
      "step": 3500
    },
    {
      "epoch": 0.8875,
      "grad_norm": 6.037752628326416,
      "learning_rate": 0.00011140000000000001,
      "loss": 2.9202,
      "step": 3550
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.932679653167725,
      "learning_rate": 0.00011015,
      "loss": 2.8381,
      "step": 3600
    },
    {
      "epoch": 0.9125,
      "grad_norm": 7.722475051879883,
      "learning_rate": 0.0001089,
      "loss": 2.788,
      "step": 3650
    },
    {
      "epoch": 0.925,
      "grad_norm": 5.824307918548584,
      "learning_rate": 0.00010765,
      "loss": 2.9159,
      "step": 3700
    },
    {
      "epoch": 0.9375,
      "grad_norm": 8.152589797973633,
      "learning_rate": 0.00010640000000000001,
      "loss": 2.7495,
      "step": 3750
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.885190486907959,
      "learning_rate": 0.00010515000000000002,
      "loss": 2.6902,
      "step": 3800
    },
    {
      "epoch": 0.9625,
      "grad_norm": 8.480701446533203,
      "learning_rate": 0.00010389999999999999,
      "loss": 2.6678,
      "step": 3850
    },
    {
      "epoch": 0.975,
      "grad_norm": 6.438226222991943,
      "learning_rate": 0.00010265,
      "loss": 2.7699,
      "step": 3900
    },
    {
      "epoch": 0.9875,
      "grad_norm": 6.921266555786133,
      "learning_rate": 0.00010140000000000001,
      "loss": 2.8913,
      "step": 3950
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.703295707702637,
      "learning_rate": 0.00010015000000000001,
      "loss": 2.7655,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.7956972122192383,
      "eval_runtime": 17.2901,
      "eval_samples_per_second": 115.673,
      "eval_steps_per_second": 28.918,
      "step": 4000
    },
    {
      "epoch": 1.0125,
      "grad_norm": 5.063436508178711,
      "learning_rate": 9.89e-05,
      "loss": 2.5867,
      "step": 4050
    },
    {
      "epoch": 1.025,
      "grad_norm": 7.7670722007751465,
      "learning_rate": 9.765e-05,
      "loss": 2.6153,
      "step": 4100
    },
    {
      "epoch": 1.0375,
      "grad_norm": 6.628337383270264,
      "learning_rate": 9.64e-05,
      "loss": 2.5476,
      "step": 4150
    },
    {
      "epoch": 1.05,
      "grad_norm": 7.159035682678223,
      "learning_rate": 9.515000000000001e-05,
      "loss": 2.5426,
      "step": 4200
    },
    {
      "epoch": 1.0625,
      "grad_norm": 8.293180465698242,
      "learning_rate": 9.39e-05,
      "loss": 2.5725,
      "step": 4250
    },
    {
      "epoch": 1.075,
      "grad_norm": 6.736722469329834,
      "learning_rate": 9.265e-05,
      "loss": 2.6389,
      "step": 4300
    },
    {
      "epoch": 1.0875,
      "grad_norm": 7.330951690673828,
      "learning_rate": 9.140000000000001e-05,
      "loss": 2.5636,
      "step": 4350
    },
    {
      "epoch": 1.1,
      "grad_norm": 5.762526988983154,
      "learning_rate": 9.015e-05,
      "loss": 2.6601,
      "step": 4400
    },
    {
      "epoch": 1.1125,
      "grad_norm": 6.515648365020752,
      "learning_rate": 8.89e-05,
      "loss": 2.6437,
      "step": 4450
    },
    {
      "epoch": 1.125,
      "grad_norm": 7.490216255187988,
      "learning_rate": 8.765e-05,
      "loss": 2.5516,
      "step": 4500
    },
    {
      "epoch": 1.1375,
      "grad_norm": 5.863382816314697,
      "learning_rate": 8.64e-05,
      "loss": 2.5677,
      "step": 4550
    },
    {
      "epoch": 1.15,
      "grad_norm": 8.176559448242188,
      "learning_rate": 8.515000000000001e-05,
      "loss": 2.6803,
      "step": 4600
    },
    {
      "epoch": 1.1625,
      "grad_norm": 6.523552894592285,
      "learning_rate": 8.39e-05,
      "loss": 2.52,
      "step": 4650
    },
    {
      "epoch": 1.175,
      "grad_norm": 7.314258098602295,
      "learning_rate": 8.265e-05,
      "loss": 2.4603,
      "step": 4700
    },
    {
      "epoch": 1.1875,
      "grad_norm": 5.685319900512695,
      "learning_rate": 8.14e-05,
      "loss": 2.6352,
      "step": 4750
    },
    {
      "epoch": 1.2,
      "grad_norm": 5.743593215942383,
      "learning_rate": 8.015e-05,
      "loss": 2.5404,
      "step": 4800
    },
    {
      "epoch": 1.2125,
      "grad_norm": 5.999708652496338,
      "learning_rate": 7.890000000000001e-05,
      "loss": 2.4644,
      "step": 4850
    },
    {
      "epoch": 1.225,
      "grad_norm": 6.436795234680176,
      "learning_rate": 7.765e-05,
      "loss": 2.5673,
      "step": 4900
    },
    {
      "epoch": 1.2375,
      "grad_norm": 9.359219551086426,
      "learning_rate": 7.64e-05,
      "loss": 2.5981,
      "step": 4950
    },
    {
      "epoch": 1.25,
      "grad_norm": 9.347064018249512,
      "learning_rate": 7.515e-05,
      "loss": 2.5952,
      "step": 5000
    },
    {
      "epoch": 1.2625,
      "grad_norm": 9.211087226867676,
      "learning_rate": 7.390000000000001e-05,
      "loss": 2.581,
      "step": 5050
    },
    {
      "epoch": 1.275,
      "grad_norm": 5.20064640045166,
      "learning_rate": 7.265e-05,
      "loss": 2.5115,
      "step": 5100
    },
    {
      "epoch": 1.2875,
      "grad_norm": 4.796946048736572,
      "learning_rate": 7.14e-05,
      "loss": 2.6631,
      "step": 5150
    },
    {
      "epoch": 1.3,
      "grad_norm": 7.21962833404541,
      "learning_rate": 7.015000000000001e-05,
      "loss": 2.6125,
      "step": 5200
    },
    {
      "epoch": 1.3125,
      "grad_norm": 8.547858238220215,
      "learning_rate": 6.89e-05,
      "loss": 2.5176,
      "step": 5250
    },
    {
      "epoch": 1.325,
      "grad_norm": 5.609112739562988,
      "learning_rate": 6.765e-05,
      "loss": 2.6382,
      "step": 5300
    },
    {
      "epoch": 1.3375,
      "grad_norm": 8.157079696655273,
      "learning_rate": 6.64e-05,
      "loss": 2.6389,
      "step": 5350
    },
    {
      "epoch": 1.35,
      "grad_norm": 6.753570556640625,
      "learning_rate": 6.515e-05,
      "loss": 2.5188,
      "step": 5400
    },
    {
      "epoch": 1.3625,
      "grad_norm": 8.883932113647461,
      "learning_rate": 6.390000000000001e-05,
      "loss": 2.5992,
      "step": 5450
    },
    {
      "epoch": 1.375,
      "grad_norm": 8.362058639526367,
      "learning_rate": 6.264999999999999e-05,
      "loss": 2.5606,
      "step": 5500
    },
    {
      "epoch": 1.3875,
      "grad_norm": 5.876409530639648,
      "learning_rate": 6.14e-05,
      "loss": 2.4989,
      "step": 5550
    },
    {
      "epoch": 1.4,
      "grad_norm": 7.401960849761963,
      "learning_rate": 6.0150000000000005e-05,
      "loss": 2.5571,
      "step": 5600
    },
    {
      "epoch": 1.4125,
      "grad_norm": 6.404128074645996,
      "learning_rate": 5.89e-05,
      "loss": 2.5115,
      "step": 5650
    },
    {
      "epoch": 1.425,
      "grad_norm": 5.572893142700195,
      "learning_rate": 5.7650000000000005e-05,
      "loss": 2.5871,
      "step": 5700
    },
    {
      "epoch": 1.4375,
      "grad_norm": 6.65437650680542,
      "learning_rate": 5.6399999999999995e-05,
      "loss": 2.5552,
      "step": 5750
    },
    {
      "epoch": 1.45,
      "grad_norm": 7.272021770477295,
      "learning_rate": 5.515e-05,
      "loss": 2.6582,
      "step": 5800
    },
    {
      "epoch": 1.4625,
      "grad_norm": 7.22952938079834,
      "learning_rate": 5.390000000000001e-05,
      "loss": 2.5176,
      "step": 5850
    },
    {
      "epoch": 1.475,
      "grad_norm": 8.231858253479004,
      "learning_rate": 5.265e-05,
      "loss": 2.5355,
      "step": 5900
    },
    {
      "epoch": 1.4875,
      "grad_norm": 6.205739974975586,
      "learning_rate": 5.14e-05,
      "loss": 2.6421,
      "step": 5950
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.310657501220703,
      "learning_rate": 5.015e-05,
      "loss": 2.5501,
      "step": 6000
    },
    {
      "epoch": 1.5125,
      "grad_norm": 6.444613933563232,
      "learning_rate": 4.89e-05,
      "loss": 2.4597,
      "step": 6050
    },
    {
      "epoch": 1.525,
      "grad_norm": 8.776007652282715,
      "learning_rate": 4.765e-05,
      "loss": 2.5625,
      "step": 6100
    },
    {
      "epoch": 1.5375,
      "grad_norm": 7.247659206390381,
      "learning_rate": 4.6425000000000004e-05,
      "loss": 2.5842,
      "step": 6150
    },
    {
      "epoch": 1.55,
      "grad_norm": 7.088435649871826,
      "learning_rate": 4.5175e-05,
      "loss": 2.5564,
      "step": 6200
    },
    {
      "epoch": 1.5625,
      "grad_norm": 8.140388488769531,
      "learning_rate": 4.3925e-05,
      "loss": 2.6492,
      "step": 6250
    },
    {
      "epoch": 1.575,
      "grad_norm": 4.3771233558654785,
      "learning_rate": 4.2675e-05,
      "loss": 2.5166,
      "step": 6300
    },
    {
      "epoch": 1.5875,
      "grad_norm": 10.99964714050293,
      "learning_rate": 4.1425000000000004e-05,
      "loss": 2.5321,
      "step": 6350
    },
    {
      "epoch": 1.6,
      "grad_norm": 6.255010604858398,
      "learning_rate": 4.0175e-05,
      "loss": 2.5182,
      "step": 6400
    },
    {
      "epoch": 1.6125,
      "grad_norm": 9.885553359985352,
      "learning_rate": 3.8925e-05,
      "loss": 2.3789,
      "step": 6450
    },
    {
      "epoch": 1.625,
      "grad_norm": 8.716320037841797,
      "learning_rate": 3.7675e-05,
      "loss": 2.5046,
      "step": 6500
    },
    {
      "epoch": 1.6375,
      "grad_norm": 8.024999618530273,
      "learning_rate": 3.6425000000000004e-05,
      "loss": 2.508,
      "step": 6550
    },
    {
      "epoch": 1.65,
      "grad_norm": 7.345621109008789,
      "learning_rate": 3.5175e-05,
      "loss": 2.6273,
      "step": 6600
    },
    {
      "epoch": 1.6625,
      "grad_norm": 7.341466426849365,
      "learning_rate": 3.3925e-05,
      "loss": 2.5784,
      "step": 6650
    },
    {
      "epoch": 1.675,
      "grad_norm": 7.579375267028809,
      "learning_rate": 3.2675e-05,
      "loss": 2.4852,
      "step": 6700
    },
    {
      "epoch": 1.6875,
      "grad_norm": 7.342956066131592,
      "learning_rate": 3.1425e-05,
      "loss": 2.5135,
      "step": 6750
    },
    {
      "epoch": 1.7,
      "grad_norm": 5.641208171844482,
      "learning_rate": 3.0175e-05,
      "loss": 2.5722,
      "step": 6800
    },
    {
      "epoch": 1.7125,
      "grad_norm": 4.851776599884033,
      "learning_rate": 2.8925000000000002e-05,
      "loss": 2.3355,
      "step": 6850
    },
    {
      "epoch": 1.725,
      "grad_norm": 5.632253646850586,
      "learning_rate": 2.7675000000000002e-05,
      "loss": 2.585,
      "step": 6900
    },
    {
      "epoch": 1.7375,
      "grad_norm": 7.153964996337891,
      "learning_rate": 2.6425e-05,
      "loss": 2.4257,
      "step": 6950
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.717437744140625,
      "learning_rate": 2.5175e-05,
      "loss": 2.4398,
      "step": 7000
    },
    {
      "epoch": 1.7625,
      "grad_norm": 9.943439483642578,
      "learning_rate": 2.3925e-05,
      "loss": 2.5946,
      "step": 7050
    },
    {
      "epoch": 1.775,
      "grad_norm": 7.250336170196533,
      "learning_rate": 2.2675000000000002e-05,
      "loss": 2.6063,
      "step": 7100
    },
    {
      "epoch": 1.7875,
      "grad_norm": 7.704000949859619,
      "learning_rate": 2.1425e-05,
      "loss": 2.5589,
      "step": 7150
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.162897109985352,
      "learning_rate": 2.0175000000000003e-05,
      "loss": 2.5669,
      "step": 7200
    },
    {
      "epoch": 1.8125,
      "grad_norm": 6.296899318695068,
      "learning_rate": 1.8925000000000003e-05,
      "loss": 2.5001,
      "step": 7250
    },
    {
      "epoch": 1.825,
      "grad_norm": 8.72211742401123,
      "learning_rate": 1.7675e-05,
      "loss": 2.3625,
      "step": 7300
    },
    {
      "epoch": 1.8375,
      "grad_norm": 9.955755233764648,
      "learning_rate": 1.6425000000000003e-05,
      "loss": 2.5337,
      "step": 7350
    },
    {
      "epoch": 1.85,
      "grad_norm": 4.822574615478516,
      "learning_rate": 1.5175e-05,
      "loss": 2.5536,
      "step": 7400
    },
    {
      "epoch": 1.8625,
      "grad_norm": 6.0803070068359375,
      "learning_rate": 1.3925000000000001e-05,
      "loss": 2.4347,
      "step": 7450
    },
    {
      "epoch": 1.875,
      "grad_norm": 8.483104705810547,
      "learning_rate": 1.2675000000000001e-05,
      "loss": 2.5147,
      "step": 7500
    },
    {
      "epoch": 1.8875,
      "grad_norm": 5.746531009674072,
      "learning_rate": 1.1425000000000002e-05,
      "loss": 2.579,
      "step": 7550
    },
    {
      "epoch": 1.9,
      "grad_norm": 9.137446403503418,
      "learning_rate": 1.0175e-05,
      "loss": 2.5629,
      "step": 7600
    },
    {
      "epoch": 1.9125,
      "grad_norm": 8.232760429382324,
      "learning_rate": 8.925e-06,
      "loss": 2.5838,
      "step": 7650
    },
    {
      "epoch": 1.925,
      "grad_norm": 6.72733211517334,
      "learning_rate": 7.675e-06,
      "loss": 2.5506,
      "step": 7700
    },
    {
      "epoch": 1.9375,
      "grad_norm": 6.975920677185059,
      "learning_rate": 6.425e-06,
      "loss": 2.5188,
      "step": 7750
    },
    {
      "epoch": 1.95,
      "grad_norm": 5.648254871368408,
      "learning_rate": 5.175e-06,
      "loss": 2.5914,
      "step": 7800
    },
    {
      "epoch": 1.9625,
      "grad_norm": 6.52911901473999,
      "learning_rate": 3.9250000000000005e-06,
      "loss": 2.5169,
      "step": 7850
    },
    {
      "epoch": 1.975,
      "grad_norm": 7.338090419769287,
      "learning_rate": 2.6750000000000002e-06,
      "loss": 2.3329,
      "step": 7900
    },
    {
      "epoch": 1.9875,
      "grad_norm": 6.289533615112305,
      "learning_rate": 1.4250000000000001e-06,
      "loss": 2.5612,
      "step": 7950
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.724973201751709,
      "learning_rate": 1.7500000000000002e-07,
      "loss": 2.4721,
      "step": 8000
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.6612608432769775,
      "eval_runtime": 17.3094,
      "eval_samples_per_second": 115.544,
      "eval_steps_per_second": 28.886,
      "step": 8000
    }
  ],
  "logging_steps": 50,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5302763926578432.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
